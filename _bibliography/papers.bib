---
---

@string{aps = {American Physical Society,}}
@string{icra = {International Conference on Robotics and Automation}}
@string{l4dc = {Conference on Learning for Dynamics and Control}}
@string{l4dc = {Conference on Learning for Dynamics and Control}}
@string{ijrr = {International Journal of Robotics Research}}
@string{rss = {Robotics: Science and Systems}}
@string{iros = {International Conference on Intelligent Robots and Systems}}
@string{iclr = {International Conference on Learning Representations}}

This one shows how to add a gif. bibtex_show={true} tells it to add a bibtex button.

book{einstein1956investigations,
  bibtex_show={true},
  title={Investigations on the Theory of the Brownian Movement},
  author={Einstein, Albert},
  year={1956},
  publisher={Courier Corporation},
  preview={brownian-motion.gif}
}

This one shows a whole bunch of useful fields used by Jekyll.

article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={false},
  inspirehep_id = {3255}
}


This one has award fields if I ever win one of those lol
Article{einstein1905photoelectriceffect,
  bibtex_show={true},
  abbr={Ann. Phys.},
  title="{{\"U}ber einen die Erzeugung und Verwandlung des Lichtes betreffenden heuristischen Gesichtspunkt}",
  author={Albert Einstein},
  abstract={This is the abstract text.},
  journal={Ann. Phys.},
  volume={322},
  number={6},
  pages={132--148},
  year={1905},
  doi={10.1002/andp.19053220607},
  award={Albert Einstein receveid the **Nobel Prize in Physics** 1921 *for his services to Theoretical Physics, and especially for his discovery of the law of the photoelectric effect*},
  award_name={Nobel Prize}
}

@inproceedings{Theodoropoulos25,
  title={Feedback Schr{\"o}dinger Bridge Matching},
  author={Theodoropoulos, Panagiotis and Komianos, Nikolaos and Pacelli, Vincent and Liu, Guan-Horng and Theodorou, Evangelos A.},
  booktitle=iclr,
  year={2025},

  selected={true},
  bibtex_show={true},
  abstract={Recent advancements in diffusion bridges for distribution transport problems have heavily relied on matching frameworks, yet existing methods often face a trade-off between scalability and access to optimal pairings during training. Fully unsupervised methods make minimal assumptions but incur high computational costs, limiting their practicality. On the other hand, imposing full supervision of the matching process with optimal pairings improves scalability, however, it can be infeasible in most applications. To strike a balance between scalability and minimal supervision, we introduce Feedback Schrödinger Bridge Matching (FSBM), a novel semi-supervised matching framework that incorporates a small portion (% of the entire dataset) of pre-aligned pairs as state feedback to guide the transport map of non-coupled samples, thereby significantly improving efficiency. This is achieved by formulating a static Entropic Optimal Transport (EOT) problem with an additional term capturing the semi-supervised guidance. The generalized EOT objective is then recast into a dynamic formulation to leverage the scalability of matching frameworks. Extensive experiments demonstrate that FSBM accelerates training and enhances generalization by leveraging coupled pairs' guidance, opening new avenues for training matching frameworks with partially aligned datasets.},
  url={https://openreview.net/forum?id=k3tbMMW8rH},
  arxiv={2410.14055},
  doi={10.48550/arXiv.2410.14055}
}

inproceedings{Saravanos25,
  title={Deep Distributed Optimization for Large-Scale Quadratic Programming},
  author={Saravanos, Augustinos D. and Kuperman, Hunter and Oshin, Alex and Abdul, Arshiya Taj and Pacelli, Vincent and Theodorou, Evangelos},
  booktitle=iclr,
  year={2025},

  selected={true},
  bibtex_show={true},
  abstract={Quadratic programming (QP) forms a crucial foundation in optimization, encompassing a broad spectrum of domains and serving as the basis for more advanced algorithms. Consequently, as the scale and complexity of modern applications continue to grow, the development of efficient and reliable QP algorithms is becoming increasingly vital. In this context, this paper introduces a novel deep learning-aided distributed optimization architecture designed for tackling large-scale QP problems. First, we combine the state-of-the-art Operator Splitting QP (OSQP) method with a consensus approach to derive DistributedQP, a new method tailored for network-structured problems, with convergence guarantees to optimality. Subsequently, we unfold this optimizer into a deep learning framework, leading to DeepDistributedQP, which leverages learned policies to accelerate reaching to desired accuracy within a restricted amount of iterations. Our approach is also theoretically grounded through Probably Approximately Correct (PAC)-Bayes theory, providing generalization bounds on the expected optimality gap for unseen problems. The proposed framework, as well as its centralized version DeepQP, significantly outperform their standard optimization counterparts on a variety of tasks such as randomly generated problems, optimal control, linear regression, transportation networks and others. Notably, DeepDistributedQP demonstrates strong generalization by training on small problems and scaling to solve much larger ones (up to 50K variables and 150K constraints) using the same policy. Moreover, it achieves orders-of-magnitude improvements in wall-clock time compared to OSQP. The certifiable performance guarantees of our approach are also demonstrated, ensuring higher-quality solutions over traditional optimizers.},
  url={https://openreview.net/forum?id=hzuumhfYSO},
  arxiv={https://arxiv.org/abs/2412.12156},
  doi={10.48550/arXiv.2412.12156}
}

@article{Ratheesh2025,
  title={Operator Splitting Covariance Steering for Safe Stochastic Nonlinear Control},
  author={Ratheesh, Akash and Pacelli, Vincent and Saravanos, Augustinos D. and Theodorou, Evangelos A.},
  journal={arXiv preprint arXiv:2411.11211},
  year={2025},

  bibtex_show={true},
  abstract={Most robotics applications are typically accompanied with safety restrictions that need to be satisfied with a high degree of confidence even in environments under uncertainty. Controlling the state distribution of a system and enforcing such specifications as distribution constraints is a promising approach for meeting such requirements. In this direction, covariance steering (CS) is an increasingly popular stochastic optimal control (SOC) framework for designing safe controllers via explicit constraints on the system covariance. Nevertheless, a major challenge in applying CS methods to systems with the nonlinear dynamics and chance constraints common in robotics is that the approximations needed are conservative and highly sensitive to the point of approximation. This can cause sequential convex programming methods to converge to poor local minima or incorrectly report problems as infeasible due to shifting constraints. This paper presents a novel algorithm for solving chance-constrained nonlinear CS problems that directly addresses this challenge. Specifically, we propose an operator-splitting approach that temporarily separates the main problem into subproblems that can be solved in parallel. The benefit of this relaxation lies in the fact that it does not require all iterates to satisfy all constraints simultaneously prior to convergence, thus enhancing the exploration capabilities of the algorithm for finding better solutions. Simulation results verify the ability of the proposed method to find higher quality solutions under stricter safety constraints than standard methods on a variety of robotic systems. Finally, the applicability of the algorithm on real systems is confirmed through hardware demonstrations.}
  arxiv={2411.11211},
  doi={10.48550/arXiv.2411.11211}
}

@article{Majumdar23,
  title={Fundamental Limits for Sensor-Based Robot Control},
  author={Majumdar, Anirudha and Mei, Zhiting and Pacelli, Vincent},
  journal=ijrr,
  volume={42},
  number={12},
  pages={1051--1069},
  year={2023},
  publisher={SAGE},

  selected={true},
  bibtex_show={true},
  abstract={Our goal is to develop theory and algorithms for establishing fundamental limits on performance imposed by a robot’s sensors for a given task. In order to achieve this, we define a quantity that captures the amount of task-relevant information provided by a sensor. Using a novel version of the generalized Fano's inequality from information theory, we demonstrate that this quantity provides an upper bound on the highest achievable expected reward for one-step decision-making tasks. We then extend this bound to multi-step problems via a dynamic programming approach. We present algorithms for numerically computing the resulting bounds, and demonstrate our approach on three examples: (i) the lava problem from the literature on partially observable Markov decision processes, (ii) an example with continuous state and observation spaces corresponding to a robot catching a freely-falling object, and (iii) obstacle avoidance using a depth sensor with non-Gaussian noise. We demonstrate the ability of our approach to establish strong limits on achievable performance for these problems by comparing our upper bounds with achievable lower bounds (computed by synthesizing or learning concrete control policies).},
  url={https://journals.sagepub.com/doi/full/10.1177/02783649231190947},
  arxiv={https://arxiv.org/abs/2202.00129},
  doi={https://doi.org/10.1177/02783649231190}
}

@inproceedings{Majumdar22,
  title={Fundamental Performance Limits for Sensor-Based Robot Control and Policy Learning},
  author={Majumdar, Anirudha and Pacelli, Vincent},
  booktitle=rss,
  year={2022},

  bibtex_show={true},
  abstract={Our goal is to develop theory and algorithms for establishing fundamental limits on performance for a given task imposed by a robot's sensors. In order to achieve this, we define a quantity that captures the amount of task-relevant information provided by a sensor. Using a novel version of the generalized Fano inequality from information theory, we demonstrate that this quantity provides an upper bound on the highest achievable expected reward for one-step decision making tasks. We then extend this bound to multi-step problems via a dynamic programming approach. We present algorithms for numerically computing the resulting bounds, and demonstrate our approach on three examples: (i) the lava problem from the literature on partially observable Markov decision processes, (ii) an example with continuous state and observation spaces corresponding to a robot catching a freely-falling object, and (iii) obstacle avoidance using a depth sensor with non-Gaussian noise. We demonstrate the ability of our approach to establish strong limits on achievable performance for these problems by comparing our upper bounds with achievable lower bounds (computed by synthesizing or learning concrete control policies).},
  url={https://roboticsconference.org/2022/program/papers/036/},
  arxiv={2202.00129v2},
  doi={https://doi.org/10.15607/rss.2022.xviii.036}
}

@inproceedings{Pacelli22,
  title={Robust Control Under Uncertainty via Bounded Rationality and Differential Privacy},
  author={Pacelli, Vincent and Majumdar, Anirudha},
  booktitle=icra,
  pages={3467--3474},
  year={2022},
  organization={IEEE},

  selected={true},
  bibtex_show={true},
  url={https://ieeexplore.ieee.org/abstract/document/9811557},
  arxiv={2109.08262},
  abstract={The rapid development of affordable and compact high-fidelity sensors (e.g., cameras and LIDAR) allows robots to construct detailed estimates of their states and environments. However, the availability of such rich sensor information introduces two challenges: (i) the lack of analytic sensing models, which makes it difficult to design controllers that are robust to sensor failures, and (ii) the computational expense of processing the high-dimensional sensor information in real time. This paper addresses these challenges using the theory of differential privacy, which allows us to (i) design controllers with bounded sensitivity to errors in state estimates, and (ii) bound the amount of state information used for control (i.e., to impose decision-making under bounded rationality). The resulting framework approximates the separation principle and allows us to derive an upper-bound on the cost incurred with a faulty state estimator in terms of three quantities: the cost incurred using a perfect state estimator, the magnitude of state estimation errors, and the level of differential privacy. We demonstrate the efficacy of our framework numerically on different robotics problems, including nonlinear system stabilization and motion planning.},
  doi={10.1109/icra46639.2022.9811557}
}


@inproceedings{Sonar2021,
  title={Invariant Policy Optimization: Towards Stronger Generalization in Reinforcement Learning},
  author={Sonar, Anoopkumar and Pacelli, Vincent and Majumdar, Anirudha},
  booktitle=l4dc,
  pages={21--33},
  year={2021},
  organization={PMLR},

  selected={true},
  bibtex_show={true},
  url={https://proceedings.mlr.press/v144/sonar21a.html},
  arxiv={2006.01096},
  abstract={A fundamental challenge in reinforcement learning is to learn policies that generalize beyond the operating domains experienced during training. In this paper, we approach this challenge through the following invariance principle: an agent must find a representation such that there exists an action-predictor built on top of this representation that is simultaneously optimal across all training domains. Intuitively, the resulting invariant policy enhances generalization by finding causes of successful actions. We propose a novel learning algorithm, Invariant Policy Optimization (IPO), that implements this principle and learns an invariant policy during training. We compare our approach with standard policy gradient methods and demonstrate significant improvements in generalization performance on unseen domains for linear quadratic regulator and grid-world problems, and an example where a robot must learn to open doors with varying physical properties.},
  doi={10.48550/arXiv.2006.01096}
}

@patent{mangharam22,
  author={Mangharam, Rahul and O'Kelly, Matthew Edward and Pacelli, Vincent Scott and Brady, Matthew Anthony},
  assignee={University of Pennsylvania},
  address={Philadelphia, PA},
  title={Systems of Stacking Interlocking Blocks},
  nationality={U.S.},
  number={11213747 B2},
  day={4},
  month={jan},
  year={2022}
}

@unpublished{Pacelli21,
  title={Robust Control for Robots via Minimal-Information Policies},
  author={Pacelli, Vincent and Majumdar, Anirudha},
  title={APS March Meeting},
  volume={2021},
  pages={Y14.003},
  year={2021},

  type={talk}
}

@inproceedings{Pacelli20, 
    author={Pacelli, Vincent and Majumdar, Anirudha}, 
    title={{Learning Task-Driven Control Policies via Information Bottlenecks}}, 
    booktitle=rss, 
    year={2020}, 
    address={Corvalis, Oregon, USA}, 
    month={July},

    bibtex_show={true},
    url={https://www.roboticsproceedings.org/rss16/p101.html},
    arxiv={2002.01428},
    abstract={This paper presents a reinforcement learning approach to synthesizing task-driven control policies for robotic systems equipped with rich sensory modalities (e.g., vision or depth). Standard reinforcement learning algorithms typically produce policies that tightly couple control actions to the entirety of the system's state and rich sensor observations. As a consequence, the resulting policies can often be sensitive to changes in task-irrelevant portions of the state or observations (e.g., changing background colors). In contrast, the approach we present here learns to create a task-driven representation that is used to compute control actions. Formally, this is achieved by deriving a policy gradient-style algorithm that creates an information bottleneck between the states and the task-driven representation; this constrains actions to only depend on task-relevant information. We demonstrate our approach in a thorough set of simulation results on multiple examples including a grasping task that utilizes depth images and a ball-catching task that utilizes RGB images. Comparisons with a standard policy gradient approach demonstrate that the task-driven policies produced by our algorithm are often significantly more robust to sensor noise and task-irrelevant changes in the environment.},
    doi={10.15607/rss.2020.xvi.101}
}

@inproceedings{Pacelli18,
  title={Integration of Local Geometry and Metric Information in Sampling-Based Motion Planning},
  author={Pacelli, Vincent and Arslan, Omur and Koditschek, Daniel E.},
  booktitle=icra,
  pages={3061--3068},
  year={2018},
  organization={IEEE},

  bibtex_show={true},
  url={https://ieeexplore.ieee.org/abstract/document/8460739},
  abstract={The efficiency of sampling-based motion planning algorithms is dependent on how well a steering procedure is capable of capturing both system dynamics and configuration space geometry to connect sample configurations. This paper considers how metrics describing local system dynamics may be combined with convex subsets of the free space to describe the local behavior of a steering function for sampling-based planners. Subsequently, a framework for using these subsets to extend the steering procedure to incorporate this information is introduced. To demonstrate our framework, three specific metrics are considered: the LQR cost-to-go function, a Gram matrix derived from system linearization, and the Mahalanobis distance of a linear-Gaussian system. Finally, numerical tests are conducted for a second-order linear system, a kinematic unicycle, and a linear-Gaussian system to demonstrate that our framework increases the connectivity of sampling-based planners and allows them to better explore the free space.},
  doi={10.1109/icra.2018.8460739}
}


@inproceedings{Arslan17,
  title={Sensory Steering for Sampling-Based Motion Planning},
  author={Arslan, Omur and Pacelli, Vincent and Koditschek, Daniel E.},
  booktitle=iros,
  pages={3708--3715},
  year={2017},
  organization={IEEE},

  bibtex_show={true},
  url={https://ieeexplore.ieee.org/abstract/document/8206218},
  abstract={Sampling-based algorithms offer computationally efficient, practical solutions to the path finding problem in high-dimensional complex configuration spaces by approximately capturing the connectivity of the underlying space through a (dense) collection of sample configurations joined by simple local planners. In this paper, we address a long-standing bottleneck associated with the difficulty of finding paths through narrow passages. Whereas most prior work considers the narrow passage problem as a sampling issue (and the literature abounds with heuristic sampling strategies) very little attention has been paid to the design of new effective local planners. Here, we propose a novel sensory steering algorithm for sampling-based motion planning that can “feel” a configuration space locally and significantly improve the path planning performance near difficult regions such as narrow passages. We provide computational evidence for the effectiveness of the proposed local planner through a variety of simulations which suggest that our proposed sensory steering algorithm outperforms the standard straight-line planner by significantly increasing the connectivity of random motion planning graphs.},
  doi={10.1109/iros.2017.8206218}
}